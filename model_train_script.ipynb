{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {
    "cellId": "qfuzm4n3wnvdlpbf7xjyi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "v5oudi7ufujookrqv0a8"
   },
   "source": [
    "### Считывание словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1967,
   "metadata": {
    "cellId": "9gejf2tbsjj96y4hzyzd45"
   },
   "outputs": [],
   "source": [
    "# десериализация словаря\n",
    "with open('token_to_id.pickle', 'rb') as file:\n",
    "    token_to_id = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "q0kq1sh0xy91limbg6r7h"
   },
   "source": [
    "### Создание Dataset и Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "metadata": {
    "cellId": "zrboqf77xkclwtva7rp67l"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from dataloader import LipReadingVideoDataset, get_vframes, collate_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1960,
   "metadata": {
    "cellId": "ord2yniucknbbg80lsvojn"
   },
   "outputs": [],
   "source": [
    "# path to dataset\n",
    "trainval_data_path = os.path.normpath('data/lrs3_trainval.zip')\n",
    "test_data_path = os.path.normpath('data/lrs3_test_v0.4.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1898,
   "metadata": {
    "cellId": "1g39nsns0ebac1kw46tyxj",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transforms for video\n",
    "from torchvideotransforms import video_transforms\n",
    "\n",
    "flip = video_transforms.RandomHorizontalFlip(p=0.5)\n",
    "rotation = video_transforms.RandomRotation(degrees=15)\n",
    "\n",
    "transform = video_transforms.Compose([flip, rotation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {
    "cellId": "j7s7asqvuns600n8qd0ar"
   },
   "outputs": [],
   "source": [
    "# tokenizer for sentences\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1961,
   "metadata": {
    "cellId": "q3c59k2wemgqezj0k2wtom"
   },
   "outputs": [],
   "source": [
    "batch = 2\n",
    "\n",
    "# load trainval\n",
    "trainval_ds = LipReadingVideoDataset(trainval_data_path, transform=transform, tokenizer=tokenizer)\n",
    "\n",
    "N = len(trainval_ds)\n",
    "train_N = int(0.9*N)\n",
    "val_N = N - train_N\n",
    "train_ds, val_ds = torch.utils.data.random_split(trainval_ds, (train_N, val_N), \n",
    "                                                 generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)\n",
    "\n",
    "# load test\n",
    "test_ds = LipReadingVideoDataset(test_data_path, transform=transform)\n",
    "test_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "zzczmqijs3hkwywhy7lvp"
   },
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1906,
   "metadata": {
    "cellId": "onpporo3iq63aylquzbkd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from network import LipReadinNN\n",
    "from network_small import LipReadinNN_LSTM\n",
    "from model_train_functions import train_model, test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1907,
   "metadata": {
    "cellId": "ng5kp0jc83z0p1lk0mbz"
   },
   "outputs": [],
   "source": [
    "# создаем модель \n",
    "lip_reading_nn = LipReadinNN_LSTM(token_to_id)\n",
    "\n",
    "opt = torch.optim.Adam(lip_reading_nn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1835,
   "metadata": {
    "cellId": "4sa2yi7141k6yt3odte0bs",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LipReadinNN_LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).\n\tsize mismatch for LSTM1.weight_ih_l0: copying a param with shape torch.Size([8192, 512]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for LSTM1.weight_hh_l0: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.weight_ih_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.weight_hh_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM2.weight_ih_l0: copying a param with shape torch.Size([4096, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for LSTM2.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.weight_ih_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.weight_hh_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f4b8997b3a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlip_reading_nn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLipReadinNN_LSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlip_reading_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlip_reading_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1224\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1225\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LipReadinNN_LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).\n\tsize mismatch for LSTM1.weight_ih_l0: copying a param with shape torch.Size([8192, 512]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for LSTM1.weight_hh_l0: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.weight_ih_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.weight_hh_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM2.weight_ih_l0: copying a param with shape torch.Size([4096, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for LSTM2.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.weight_ih_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.weight_hh_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512])."
     ]
    }
   ],
   "source": [
    "# или загружаем модель\n",
    "PATH = 'lip_reading/model_0.pt'\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "\n",
    "lip_reading_nn = LipReadinNN_LSTM(token_to_id)\n",
    "lip_reading_nn.load_state_dict(torch.load(PATH))\n",
    "lip_reading_nn.to(device)\n",
    "\n",
    "opt = torch.optim.Adam(lip_reading_nn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {
    "cellId": "q3jyp8dxghlnnkrzlergt",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train step\n",
      "|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||val step\n",
      "test step\n",
      "test cycle step\n",
      "test cycle step\n",
      "test cycle step\n",
      "test cycle step\n",
      "test cycle step\n",
      "test cycle step\n",
      "mean loss on train: \t4.336970650323547\n",
      "mean loss on val: \t6.143784364064534\n",
      "||||"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d386a4febb95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                    \u001b[0mval_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                    \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                    device=device)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     test_loss = test_model(model=lip_reading_nn, \n",
      "\u001b[0;32m~/work/resources/lip_reading/model_train_functions.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, device)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mvframes_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvframes_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvframes_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_of_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/resources/lip_reading/network_small.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_batch, target_list_of_tokens)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_len\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mframes_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, C, H, W] for resnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [batch, feature=512]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# [time, batch, feature=512] for LSTM1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2146\u001b[0m     return torch.batch_norm(\n\u001b[0;32m-> 2147\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2148\u001b[0m     )\n\u001b[1;32m   2149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# обучение\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "epoch = 3\n",
    "\n",
    "for e in range(epoch):\n",
    "    train_loss, val_loss = train_model(model=lip_reading_nn, \n",
    "                                   train_dataloader=train_dl, \n",
    "                                   val_dataloader=val_dl, \n",
    "                                   optimizer=opt, \n",
    "                                   device=device)\n",
    "    \n",
    "    test_loss = test_model(model=lip_reading_nn, \n",
    "                           test_dataloader=test_dl, \n",
    "                           device=device)\n",
    "    \n",
    "    print('')\n",
    "    print(f'EPOCH {e} is ended')\n",
    "    print(f'last mean loss on train: \\t{train_loss[-1]}')\n",
    "    print(f'last mean loss on val: \\t{val_loss[-1]}')\n",
    "    print(f'mean loss on test: \\t{np.array(test_loss).mean()}', end='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "tyhgxb3lv48o0poo4iatt"
   },
   "source": [
    "### Проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {
    "cellId": "eeyp0ao3q7i77lq7jzyg5r"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.6580, grad_fn=<NllLoss2DBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lip_reading_nn.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1962,
   "metadata": {
    "cellId": "j57kjlhj4y43ddb9bq7ki"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 128, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "for i, (vframes_batch, list_of_tokens) in enumerate(train_dl):\n",
    "    print(vframes_batch.shape)\n",
    "    if i >= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {
    "cellId": "8wcmf0la6re5vxsn4gu2t"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n",
    "vframes_batch = vframes_batch.to(device)\n",
    "\n",
    "lip_reading_nn.train(False)\n",
    "lip_reading_nn.to(device)\n",
    "\n",
    "output = lip_reading_nn(vframes_batch, list_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {
    "cellId": "enogf2kikii1ccufzbd6q"
   },
   "outputs": [],
   "source": [
    "# сохраняем модель\n",
    "PATH = 'model_.pt'\n",
    "\n",
    "torch.save(lip_reading_nn.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xzl17uswoii4vpiajo9hgg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "notebookId": "048a52f6-d27f-4aa8-ba2c-9994e100de23"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
