{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3"},"notebookId":"048a52f6-d27f-4aa8-ba2c-9994e100de23"},"cells":[{"cell_type":"code","source":"import os\nimport zipfile\nimport pickle\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n#import cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"cellId":"qfuzm4n3wnvdlpbf7xjyi","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"}],"execution_count":1917},{"cell_type":"markdown","source":"### Считывание словаря","metadata":{"cellId":"v5oudi7ufujookrqv0a8"}},{"cell_type":"code","source":"# десериализация словаря\nwith open('token_to_id.pickle', 'rb') as file:\n    token_to_id = pickle.load(file)","metadata":{"cellId":"9gejf2tbsjj96y4hzyzd45","trusted":true},"outputs":[],"execution_count":1967},{"cell_type":"markdown","source":"### Создание Dataset и Dataloader","metadata":{"cellId":"q0kq1sh0xy91limbg6r7h"}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nfrom dataloader import LipReadingVideoDataset, get_vframes, collate_func","metadata":{"cellId":"zrboqf77xkclwtva7rp67l","trusted":true},"outputs":[],"execution_count":1966},{"cell_type":"code","source":"# path to dataset\ntrainval_data_path = os.path.normpath('data/lrs3_trainval.zip')\ntest_data_path = os.path.normpath('data/lrs3_test_v0.4.zip')","metadata":{"cellId":"ord2yniucknbbg80lsvojn","trusted":true},"outputs":[],"execution_count":1960},{"cell_type":"code","source":"# transforms for video\nfrom torchvideotransforms import video_transforms\n\nflip = video_transforms.RandomHorizontalFlip(p=0.5)\nrotation = video_transforms.RandomRotation(degrees=15)\n\ntransform = video_transforms.Compose([flip, rotation])","metadata":{"scrolled":true,"cellId":"1g39nsns0ebac1kw46tyxj","trusted":true},"outputs":[],"execution_count":1898},{"cell_type":"code","source":"# tokenizer for sentences\ntokenizer = nltk.tokenize.WordPunctTokenizer()","metadata":{"cellId":"j7s7asqvuns600n8qd0ar","trusted":true},"outputs":[],"execution_count":1948},{"cell_type":"code","source":"batch = 2\n\n# load trainval\ntrainval_ds = LipReadingVideoDataset(trainval_data_path, transform=transform, tokenizer=tokenizer)\n\nN = len(trainval_ds)\ntrain_N = int(0.9*N)\nval_N = N - train_N\ntrain_ds, val_ds = torch.utils.data.random_split(trainval_ds, (train_N, val_N), \n                                                 generator=torch.Generator().manual_seed(42))\n\ntrain_dl = torch.utils.data.DataLoader(train_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)\nval_dl = torch.utils.data.DataLoader(val_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)\n\n# load test\ntest_ds = LipReadingVideoDataset(test_data_path, transform=transform)\ntest_dl = torch.utils.data.DataLoader(test_ds, batch_size=batch, shuffle=True, collate_fn=collate_func)","metadata":{"cellId":"q3c59k2wemgqezj0k2wtom","trusted":true},"outputs":[],"execution_count":1961},{"cell_type":"markdown","source":"### Network","metadata":{"cellId":"zzczmqijs3hkwywhy7lvp"}},{"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n\nfrom network import LipReadinNN\nfrom network_small import LipReadinNN_LSTM\nfrom model_train_functions import train_model, test_model","metadata":{"cellId":"onpporo3iq63aylquzbkd","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"}],"execution_count":1906},{"cell_type":"code","source":"# создаем модель \nlip_reading_nn = LipReadinNN_LSTM(token_to_id)\n\nopt = torch.optim.Adam(lip_reading_nn.parameters(), lr=0.001)","metadata":{"cellId":"ng5kp0jc83z0p1lk0mbz","trusted":true},"outputs":[],"execution_count":1907},{"cell_type":"code","source":"# или загружаем модель\nPATH = 'lip_reading/model_0.pt'\ndevice = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\n\nlip_reading_nn = LipReadinNN_LSTM(token_to_id)\nlip_reading_nn.load_state_dict(torch.load(PATH))\nlip_reading_nn.to(device)\n\nopt = torch.optim.Adam(lip_reading_nn.parameters(), lr=0.001)","metadata":{"cellId":"4sa2yi7141k6yt3odte0bs","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for LipReadinNN_LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).\n\tsize mismatch for LSTM1.weight_ih_l0: copying a param with shape torch.Size([8192, 512]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for LSTM1.weight_hh_l0: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.weight_ih_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.weight_hh_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM2.weight_ih_l0: copying a param with shape torch.Size([4096, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for LSTM2.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.weight_ih_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.weight_hh_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)","\u001B[0;32m<ipython-input-6-f4b8997b3a41>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mlip_reading_nn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLipReadinNN_LSTM\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtoken_to_id\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0mlip_reading_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mPATH\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0mlip_reading_nn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36mload_state_dict\u001B[0;34m(self, state_dict, strict)\u001B[0m\n\u001B[1;32m   1222\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merror_msgs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1223\u001B[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001B[0;32m-> 1224\u001B[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001B[0m\u001B[1;32m   1225\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0m_IncompatibleKeys\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmissing_keys\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0munexpected_keys\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1226\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for LipReadinNN_LSTM:\n\tsize mismatch for embedding.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512]).\n\tsize mismatch for LSTM1.weight_ih_l0: copying a param with shape torch.Size([8192, 512]) from checkpoint, the shape in current model is torch.Size([4096, 512]).\n\tsize mismatch for LSTM1.weight_hh_l0: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l0: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.weight_ih_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.weight_hh_l1: copying a param with shape torch.Size([8192, 2048]) from checkpoint, the shape in current model is torch.Size([4096, 1024]).\n\tsize mismatch for LSTM1.bias_ih_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM1.bias_hh_l1: copying a param with shape torch.Size([8192]) from checkpoint, the shape in current model is torch.Size([4096]).\n\tsize mismatch for LSTM2.weight_ih_l0: copying a param with shape torch.Size([4096, 2048]) from checkpoint, the shape in current model is torch.Size([2048, 1024]).\n\tsize mismatch for LSTM2.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.weight_ih_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.weight_hh_l1: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM2.bias_ih_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM2.bias_hh_l1: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.weight_ih_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.weight_hh_l0: copying a param with shape torch.Size([4096, 1024]) from checkpoint, the shape in current model is torch.Size([2048, 512]).\n\tsize mismatch for LSTM_decoder.bias_ih_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for LSTM_decoder.bias_hh_l0: copying a param with shape torch.Size([4096]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for linear.weight: copying a param with shape torch.Size([17193, 1024]) from checkpoint, the shape in current model is torch.Size([17193, 512])."]}],"execution_count":1835},{"cell_type":"code","source":"# обучение\ndevice = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\nepoch = 3\n\nfor e in range(epoch):\n    train_loss, val_loss = train_model(model=lip_reading_nn, \n                                   train_dataloader=train_dl, \n                                   val_dataloader=val_dl, \n                                   optimizer=opt, \n                                   device=device)\n    \n    test_loss = test_model(model=lip_reading_nn, \n                           test_dataloader=test_dl, \n                           device=device)\n    \n    print('')\n    print(f'EPOCH {e} is ended')\n    print(f'last mean loss on train: \\t{train_loss[-1]}')\n    print(f'last mean loss on val: \\t{val_loss[-1]}')\n    print(f'mean loss on test: \\t{np.array(test_loss).mean()}', end='\\n')","metadata":{"scrolled":true,"cellId":"q3jyp8dxghlnnkrzlergt","collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"train step\n|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||val step\ntest step\ntest cycle step\ntest cycle step\ntest cycle step\ntest cycle step\ntest cycle step\ntest cycle step\nmean loss on train: \t4.336970650323547\nmean loss on val: \t6.143784364064534\n||||"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m<ipython-input-14-d386a4febb95>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      8\u001B[0m                                    \u001B[0mval_dataloader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_dl\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m                                    \u001B[0moptimizer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mopt\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 10\u001B[0;31m                                    device=device)\n\u001B[0m\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m     test_loss = test_model(model=lip_reading_nn, \n","\u001B[0;32m~/work/resources/lip_reading/model_train_functions.py\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(model, train_dataloader, val_dataloader, optimizer, device)\u001B[0m\n\u001B[1;32m     42\u001B[0m         \u001B[0mvframes_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mvframes_batch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvframes_batch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist_of_tokens\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/work/resources/lip_reading/network_small.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input_batch, target_list_of_tokens)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwin_len\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mframes_num\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcolor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwidth\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# [batch, C, H, W] for resnet\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresnet18\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# [batch, feature=512]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m         \u001B[0moutput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moutput\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreshape\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mwin_len\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mframes_num\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m512\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# [time, batch, feature=512] for LSTM1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 220\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    221\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36m_forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    209\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayer4\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mavgpool\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    117\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 119\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    120\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     58\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconv1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbn1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m         \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrelu\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m    887\u001B[0m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_slow_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 889\u001B[0;31m             \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    890\u001B[0m         for hook in itertools.chain(\n\u001B[1;32m    891\u001B[0m                 \u001B[0m_global_forward_hooks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    138\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrunning_mean\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrack_running_stats\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    139\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrunning_var\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrack_running_stats\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 140\u001B[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001B[0m\u001B[1;32m    141\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/nn/functional.py\u001B[0m in \u001B[0;36mbatch_norm\u001B[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001B[0m\n\u001B[1;32m   2145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2146\u001B[0m     return torch.batch_norm(\n\u001B[0;32m-> 2147\u001B[0;31m         \u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrunning_mean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrunning_var\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtraining\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmomentum\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0meps\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackends\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcudnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menabled\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2148\u001B[0m     )\n\u001B[1;32m   2149\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"execution_count":1908},{"cell_type":"markdown","source":"### Проверки","metadata":{"cellId":"tyhgxb3lv48o0poo4iatt"}},{"cell_type":"code","source":"lip_reading_nn.loss","metadata":{"cellId":"eeyp0ao3q7i77lq7jzyg5r","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"tensor(6.6580, grad_fn=<NllLoss2DBackward>)"},"metadata":{}}],"execution_count":1914},{"cell_type":"code","source":"for i, (vframes_batch, list_of_tokens) in enumerate(train_dl):\n    print(vframes_batch.shape)\n    if i >= 0:\n        break","metadata":{"cellId":"j57kjlhj4y43ddb9bq7ki","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"torch.Size([2, 5, 128, 3, 224, 224])\n"}],"execution_count":1962},{"cell_type":"code","source":"device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda')\nvframes_batch = vframes_batch.to(device)\n\nlip_reading_nn.train(False)\nlip_reading_nn.to(device)\n\noutput = lip_reading_nn(vframes_batch, list_of_tokens)","metadata":{"cellId":"8wcmf0la6re5vxsn4gu2t","trusted":true},"outputs":[],"execution_count":1911},{"cell_type":"code","source":"# сохраняем модель\nPATH = 'model_.pt'\n\ntorch.save(lip_reading_nn.state_dict(), PATH)","metadata":{"cellId":"enogf2kikii1ccufzbd6q","trusted":true},"outputs":[],"execution_count":1915},{"cell_type":"code","source":"","metadata":{"cellId":"xzl17uswoii4vpiajo9hgg"},"outputs":[],"execution_count":null}]}