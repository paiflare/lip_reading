# Lip Reading

Чтени по губам на основе глубокой нейронной сети. 
В данном репозитории представлена модель глубокого обучения для задачи чтения по губам, используя лишь видеоряд без звуковой дорожки.

1. Структура проекта
  
  *  models/ - директория с сохраненными обученными pytorch моделями
  *  dataloader.py - код классов DataSet и DataLoader для считывания данных и обучения модели
  *  network.py - код класса LipReadingNN - нейросеть для задачи seq2seq из видеоряда в последовательность слов
  *  network_small.py - код класса LipReadingNN_LSTM - нейросеть для задачи seq2seq из видеоряда в последовательность слов
  *  model_train_functions.py - функции для обучения, валидации и тестирования модели
  *  model_train_script.ipynb - ноутбук с полным циклом создания/загрузки->обучения->сохранения модели
  *  create_tokens_dict.ipynb - создание словаря токенов для модели
  *  token_to_id.pickle - сохраненный стандартный словарь токенов
  *  main.py - скрипт для консольного запуска модели


2. Запуск

Для запуска модели необходимо склонировать репозиторий и запустить в консоли скрипт main.py передав в качестве обязательного аргумента путь к видеофайлу в формате .mp4. При желании можно указать ключ --gpu, чтобы запустить модель на видеокарте


3. Архитектура нейронной сети

Архитектура нейросети LipReadingNN основана на ResNet18 для свертки изображений и получения эмбеддингов каждого кадра. Далее LSTM слой для скользящего (вдоль времени) окна и получения скрытого состояния для каждого из таких окон. Далее Transformer Encoder (вдоль фреймов) и Transformer Decoder для получения последовательности токенов
![LipReadinNN architecture](/images/nn.jpg)

В облегченной версии LipReadingNN_LSTM Encoder и Decoder заменены на LSTM слои
![LipReadinNN_LSTM architecture](/images/nn_small.jpg)
