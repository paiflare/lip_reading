{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-authority",
   "metadata": {
    "cellId": "58jjgx327ntluxmrip2zv"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1903,
   "id": "extreme-alexander",
   "metadata": {
    "cellId": "y5klla2st5b1xrlmybv4f"
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "#tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "\n",
    "token_counts = Counter(tokenizer.tokenize(' '.join(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-cleaners",
   "metadata": {
    "cellId": "p38a0p126ti0u94lsd1vvx"
   },
   "outputs": [],
   "source": [
    "# здесь скрипт создания sentences.txt из trainval датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1902,
   "id": "social-restoration",
   "metadata": {
    "cellId": "6ihrux3otsb1pnzmxuafud"
   },
   "outputs": [],
   "source": [
    "file = open('lip_reading/sentences.txt', 'r')\n",
    "sentences = list(map(lambda line: line.strip(), file.readlines()))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1904,
   "id": "universal-butterfly",
   "metadata": {
    "cellId": "wljp1rhsntr8lan8e83osw"
   },
   "outputs": [],
   "source": [
    "min_count = 1\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = []\n",
    "for key, values in token_counts.items():\n",
    "    if values >= min_count:\n",
    "        tokens.append(key)\n",
    "\n",
    "# Add a special tokens for unknown and empty words\n",
    "BOS, EOS, UNK, PAD = '_BOS_', '_EOS_', '_UNK_', '_PAD_'\n",
    "tokens = [PAD, BOS, EOS, UNK] + tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1905,
   "id": "controlling-walker",
   "metadata": {
    "cellId": "rsc44bk1gfjf1r5xjv4o3"
   },
   "outputs": [],
   "source": [
    "# словарь\n",
    "token_to_id = {tok: i for i, tok in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "id": "lesser-retro",
   "metadata": {
    "cellId": "6ol4u06ljtuze6sjdplv0f"
   },
   "outputs": [],
   "source": [
    "# сериализация словаря\n",
    "with open('token_to_id.pickle', 'wb') as file:\n",
    "    pickle.dump(token_to_id, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-compound",
   "metadata": {
    "cellId": "lp2cxjwzp7ci4pzo7f7q9"
   },
   "outputs": [],
   "source": [
    "# десериализация словаря\n",
    "with open('token_to_id.pickle', 'rb') as file:\n",
    "    token_to_id = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "notebookId": "0691906f-c9ee-474e-8b88-1c40251b663a"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
