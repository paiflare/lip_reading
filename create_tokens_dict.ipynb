{"nbformat":4,"nbformat_minor":5,"metadata":{"notebookId":"0691906f-c9ee-474e-8b88-1c40251b663a","language_info":{"nbconvert_exporter":"python","name":"python","codemirror_mode":{"version":3,"name":"ipython"},"mimetype":"text/x-python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3"},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"code","source":"from collections import Counter\nimport nltk","metadata":{"cellId":"58jjgx327ntluxmrip2zv"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = nltk.tokenize.WordPunctTokenizer()\n#tokenizer = nltk.tokenize.TreebankWordTokenizer()\n\ntoken_counts = Counter(tokenizer.tokenize(' '.join(sentences)))","metadata":{"cellId":"y5klla2st5b1xrlmybv4f","trusted":true},"outputs":[],"execution_count":1903},{"cell_type":"code","source":"# здесь скрипт создания sentences.txt из trainval датасета","metadata":{"cellId":"p38a0p126ti0u94lsd1vvx"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"file = open('lip_reading/sentences.txt', 'r')\nsentences = list(map(lambda line: line.strip(), file.readlines()))\nfile.close()","metadata":{"cellId":"6ihrux3otsb1pnzmxuafud","trusted":true},"outputs":[],"execution_count":1902},{"cell_type":"code","source":"min_count = 1\n\n# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\ntokens = []\nfor key, values in token_counts.items():\n    if values >= min_count:\n        tokens.append(key)\n\n# Add a special tokens for unknown and empty words\nBOS, EOS, UNK, PAD = '_BOS_', '_EOS_', '_UNK_', '_PAD_'\ntokens = [PAD, BOS, EOS, UNK] + tokens","metadata":{"cellId":"wljp1rhsntr8lan8e83osw","trusted":true},"outputs":[],"execution_count":1904},{"cell_type":"code","source":"# словарь\ntoken_to_id = {tok: i for i, tok in enumerate(tokens)}","metadata":{"cellId":"rsc44bk1gfjf1r5xjv4o3","trusted":true},"outputs":[],"execution_count":1905},{"cell_type":"code","source":"# сериализация словаря\nwith open('token_to_id.pickle', 'wb') as file:\n    pickle.dump(token_to_id, file)","metadata":{"cellId":"6ol4u06ljtuze6sjdplv0f","trusted":true},"outputs":[],"execution_count":1918},{"cell_type":"code","source":"# десериализация словаря\nwith open('token_to_id.pickle', 'rb') as file:\n    token_to_id = pickle.load(file)","metadata":{"cellId":"lp2cxjwzp7ci4pzo7f7q9"},"outputs":[],"execution_count":null}]}